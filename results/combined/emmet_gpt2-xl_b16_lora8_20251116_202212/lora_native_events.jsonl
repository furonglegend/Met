{"run_dir": "results\\combined\\emmet_gpt2-xl_b16_lora8_20251116_202212", "batch_idx": 0, "layer": "17", "weight_name": "transformer.h.17.mlp.c_proj.weight", "delta_norm": 33.41008908815999, "lora_residual_rel": null, "lora_fallback": false, "lora_fallback_reason": null, "lora_rank": 8, "lora_alpha": 16.0, "lora_scale": 1.0, "lora_fit_steps": 0, "edit_mode": "lora_native"}
