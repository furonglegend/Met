[
  {
    "example_id": 0,
    "subject": "Nicholas Fairbairn",
    "target_new": "Vienna",
    "target_true": "London",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 1,
    "subject": "Alston G. Dayton",
    "target_new": "actor",
    "target_true": "politician",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.2
  },
  {
    "example_id": 2,
    "subject": "Sunday Night Baseball",
    "target_new": "CBS",
    "target_true": "ESPN",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 3,
    "subject": "Primorsky Krai",
    "target_new": "Antarctica",
    "target_true": "Asia",
    "efficacy_score": 1.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 4,
    "subject": "Henrique Maximiano Coelho Neto",
    "target_new": "Norway",
    "target_true": "Brazil",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 0.4
  },
  {
    "example_id": 5,
    "subject": "Sheryl Crow",
    "target_new": "trumpet",
    "target_true": "guitar",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 6,
    "subject": "Manuel Ferraz de Campos Sales",
    "target_new": "Spain",
    "target_true": "Brazil",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.6
  },
  {
    "example_id": 7,
    "subject": "Nintendo Software Planning & Development",
    "target_new": "Paris",
    "target_true": "Japan",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 8,
    "subject": "Karim Abdul Razak",
    "target_new": "outfielder",
    "target_true": "midfielder",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 9,
    "subject": "Norway",
    "target_new": "Rome",
    "target_true": "Oslo",
    "efficacy_score": 1.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 10,
    "subject": "Opeth",
    "target_new": "Italy",
    "target_true": "Sweden",
    "efficacy_score": 1.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 11,
    "subject": "Merisant",
    "target_new": "Montreal",
    "target_true": "Chicago",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 12,
    "subject": "Wallace Carothers",
    "target_new": "musician",
    "target_true": "chemistry",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 13,
    "subject": "The Bronx Is Burning",
    "target_new": "CNN",
    "target_true": "ESPN",
    "efficacy_score": 1.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 14,
    "subject": "Cloud Nothings",
    "target_new": "Belgium",
    "target_true": "Cleveland",
    "efficacy_score": 1.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 15,
    "subject": "Antonio Vivaldi",
    "target_new": "jazz",
    "target_true": "opera",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 0.4
  },
  {
    "example_id": 16,
    "subject": "Bernard Giraudeau",
    "target_new": "Polish",
    "target_true": "French",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 17,
    "subject": "Bob Mason",
    "target_new": "midfielder",
    "target_true": "goaltender",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.4
  },
  {
    "example_id": 18,
    "subject": "Hilary Putnam",
    "target_new": "actor",
    "target_true": "philosopher",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.6
  },
  {
    "example_id": 19,
    "subject": "Philippine Lotto Draw",
    "target_new": "Italy",
    "target_true": "Philippines",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.0
  },
  {
    "example_id": 20,
    "subject": "Loviisa",
    "target_new": "Italian",
    "target_true": "Swedish",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 21,
    "subject": "United States Patent and Trademark Office",
    "target_new": "Charlotte",
    "target_true": "Alexandria",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 22,
    "subject": "Paul Brill",
    "target_new": "Miami",
    "target_true": "Rome",
    "efficacy_score": 1.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 23,
    "subject": "Larry Stabbins",
    "target_new": "Chicago",
    "target_true": "Bristol",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.6
  },
  {
    "example_id": 24,
    "subject": "Upper Canada District School Board",
    "target_new": "Nevada",
    "target_true": "Ontario",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.6
  },
  {
    "example_id": 25,
    "subject": "Samuel Naumbourg",
    "target_new": "London",
    "target_true": "Paris",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 26,
    "subject": "Windows Mobile 6.5",
    "target_new": "Apple",
    "target_true": "Microsoft",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 27,
    "subject": "Gantz",
    "target_new": "Australia",
    "target_true": "Japan",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 28,
    "subject": "Bentley Continental",
    "target_new": "Toyota",
    "target_true": "Bentley",
    "efficacy_score": 1.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 29,
    "subject": "Passer \u00e0 l'acte",
    "target_new": "Georgian",
    "target_true": "French",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 30,
    "subject": "Cyberdog",
    "target_new": "Sega",
    "target_true": "Apple",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 31,
    "subject": "Rudolph Isley",
    "target_new": "London",
    "target_true": "Cincinnati",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.0
  },
  {
    "example_id": 32,
    "subject": "Windows Embedded Automotive",
    "target_new": "Sega",
    "target_true": "Microsoft",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 33,
    "subject": "Leo Villareal",
    "target_new": "Boston",
    "target_true": "Albuquerque",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.0
  },
  {
    "example_id": 34,
    "subject": "Trevor Dunn",
    "target_new": "politician",
    "target_true": "composer",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.4
  },
  {
    "example_id": 35,
    "subject": "Shunyi Olympic Rowing-Canoeing Park",
    "target_new": "Kuwait",
    "target_true": "Beijing",
    "efficacy_score": 1.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 36,
    "subject": "Delta Goodrem",
    "target_new": "India",
    "target_true": "Australia",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 37,
    "subject": "Yutaka Abe",
    "target_new": "Chicago",
    "target_true": "Kyoto",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 38,
    "subject": "Honda Civic Hybrid",
    "target_new": "Volvo",
    "target_true": "Honda",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 39,
    "subject": "Luca Pacioli",
    "target_new": "physics",
    "target_true": "mathematics",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 40,
    "subject": "Halvor Schou",
    "target_new": "Sacramento",
    "target_true": "Oslo",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 41,
    "subject": "Pittsburgh",
    "target_new": "Budapest",
    "target_true": "Sheffield",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.2
  },
  {
    "example_id": 42,
    "subject": "Henri Queuille",
    "target_new": "English",
    "target_true": "French",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 0.4
  },
  {
    "example_id": 43,
    "subject": "DJ Die",
    "target_new": "Madrid",
    "target_true": "Devon",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 44,
    "subject": "Jean Bourdichon",
    "target_new": "English",
    "target_true": "French",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 0.4
  },
  {
    "example_id": 45,
    "subject": "Thoranai",
    "target_new": "English",
    "target_true": "Tamil",
    "efficacy_score": 1.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 46,
    "subject": "Georgina Leonidas",
    "target_new": "composer",
    "target_true": "actor",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.5,
    "neighborhood_score": 0.8
  },
  {
    "example_id": 47,
    "subject": "Turkmenistan",
    "target_new": "Antarctica",
    "target_true": "Asia",
    "efficacy_score": 0.0,
    "paraphrase_score": 0.0,
    "neighborhood_score": 1.0
  },
  {
    "example_id": 48,
    "subject": "Ludwig Klages",
    "target_new": "chemistry",
    "target_true": "psychology",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.6
  },
  {
    "example_id": 49,
    "subject": "Gentle Ben",
    "target_new": "Netflix",
    "target_true": "CBS",
    "efficacy_score": 1.0,
    "paraphrase_score": 1.0,
    "neighborhood_score": 0.8
  }
]